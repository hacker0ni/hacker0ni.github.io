[ { "title": "The HTTP/2 Rapid Reset Vulnerability: A Critical Flaw in Modern Web Communication", "url": "/posts/http-2-reset-vuln/", "categories": "General", "tags": "", "date": "2023-10-19 00:00:00 +0000", "snippet": "The HTTP/2 Rapid Reset Vulnerability: A Critical Flaw in Modern Web CommunicationIntroductionIn the realm of web communication protocols, HTTP/2 has been a game-changer. It was designed to improve the efficiency of data transfer between clients and servers, offering enhanced speed and performance over its predecessor, HTTP/1.1. However, like all technological advancements, it’s not immune to vulnerabilities. One such vulnerability that recently emerged is the HTTP/2 Rapid Reset Vulnerability, which poses a significant threat to web security and performance. In this article, we will explore what this vulnerability is, why it matters, its potential impact, and how to mitigate the risks associated with it.The Emergence of HTTP/2HTTP/2 was standardized in 2015 to replace the aging HTTP/1.1 protocol. Its primary objective was to make web pages load faster by addressing some of the shortcomings of its predecessor. HTTP/1.1 used a text-based format for communication, which was highly inefficient, especially for serving the modern, complex web pages and applications. HTTP/2, on the other hand, introduced a binary format, multiplexing, header compression, and other performance improvements, making it a preferred choice for most web servers and browsers.The Rapid Reset VulnerabilityThe HTTP/2 Rapid Reset Vulnerability is a recent discovery that is associated with how HTTP/2 handles streams and frames. In HTTP/2, communication occurs through frames, which are divided into HEADERS frames and DATA frames. The HEADERS frames contain metadata about the resource being requested, while DATA frames carry the actual content of the resource.The vulnerability lies in the way HTTP/2 servers and clients handle the reset of streams. A stream reset is a common operation in HTTP/2, typically used when a client or server decides to abandon or restart a request for any reason. However, due to a flaw in the protocol’s design, malicious actors can exploit this operation to their advantage.Here’s how the Rapid Reset Vulnerability works: An attacker initiates a request by creating a stream, sending a HEADERS frame, and using up some server resources. Before the server responds with a DATA frame, the attacker resets the stream, claiming the reset is for any valid reason. The server, believing the attacker’s reset request, releases the resources associated with the stream. The attacker can repeat this process, creating and resetting streams, causing the server to exhaust its resources. As a result, the server becomes overwhelmed, leading to a denial-of-service (DoS) condition where legitimate requests are either delayed or entirely blocked. Why Does It Matter?The HTTP/2 Rapid Reset Vulnerability is a matter of concern for several reasons: Widespread Adoption: HTTP/2 has seen widespread adoption across the web, with most modern web servers and browsers supporting it. This means that a significant portion of web traffic is susceptible to this vulnerability. DoS Potential: The primary concern is the potential for distributed denial-of-service (DDoS) attacks. With this vulnerability, attackers can easily overwhelm servers, rendering websites and web applications inaccessible. Such attacks can be devastating for businesses and organizations relying on web services. Resource Exhaustion: The attack can lead to a significant depletion of server resources, including memory and processing power. This can impact the server’s ability to serve legitimate requests efficiently, affecting the user experience. Server Software Vulnerabilities: Many web servers use open-source software to implement HTTP/2. Vulnerabilities like the Rapid Reset Vulnerability can expose these servers to attacks and exploit their weaknesses. Impact on Web PerformanceThe Rapid Reset Vulnerability doesn’t just pose a security risk; it also has implications for web performance. When attackers exploit this vulnerability to flood servers with reset requests, it can lead to reduced server performance, slower response times, and increased latency. This ultimately affects the user experience and can lead to a loss of trust among website visitors.Mitigating the Rapid Reset VulnerabilityMitigating the HTTP/2 Rapid Reset Vulnerability requires a multi-faceted approach involving web server administrators, browser developers, and network security professionals. Here are some strategies to address this threat: Update Server Software: Web server administrators should ensure they are using the latest versions of their HTTP/2 implementation, which may include patches to address this vulnerability. Rate Limiting: Implement rate limiting to restrict the number of streams a client can create within a specified timeframe. This can help prevent resource exhaustion due to an excessive number of reset requests. Monitoring and Logging: Set up monitoring and logging to track unusual stream creation and reset patterns. This can help identify and respond to potential attacks in real-time. Web Application Firewalls (WAFs): Use WAFs that can detect and block suspicious traffic patterns associated with this vulnerability. Update Browsers: Browser developers should issue updates to address this vulnerability on the client-side. Users should keep their browsers up-to-date to benefit from these security fixes. Load Balancers: Deploy load balancers with DDoS mitigation capabilities to distribute traffic and absorb attacks, reducing the impact of the Rapid Reset Vulnerability. Network Segmentation: Implement network segmentation to isolate critical services from potentially compromised systems, reducing the attack surface. Anomaly Detection: Employ anomaly detection systems that can identify unusual behavior and patterns in network traffic, allowing for quick response to potential attacks. ConclusionThe HTTP/2 Rapid Reset Vulnerability underscores the evolving nature of cybersecurity threats in the modern digital landscape. As the internet becomes increasingly integral to our daily lives and business operations, it’s crucial to address and patch vulnerabilities promptly. The Rapid Reset Vulnerability in HTTP/2 is a stark reminder that even cutting-edge technologies can have flaws that need to be addressed to maintain a secure and efficient online environment.The responsible disclosure and swift mitigation of vulnerabilities are paramount, involving collaboration between web server administrators, browser developers, and network security professionals. By staying proactive and vigilant, the web community can collectively defend against emerging threats and ensure that HTTP/2 remains a robust and secure protocol for the foreseeable future." }, { "title": "Dropping Ransomware Payouts and Why This Is Good For The Industry", "url": "/posts/ransomware-payout-drop/", "categories": "General", "tags": "", "date": "2023-01-23 00:00:00 +0000", "snippet": "IntroRansomware attacks have been a major concern for individuals and organizations alike in recent years. These attacks involve hackers encrypting a victim’s data and demanding payment in exchange for the decryption key. According to a recent report, ransomware payouts have dropped by 40%.While this may seem like bad news for victims of ransomware attacks, it is actually a positive development for the cyber security industry. One of the reasons for the drop in payouts is that more and more organizations are refusing to pay the ransom demands. This sends a clear message to hackers that their tactics are not working and that victims will not be bullied into paying up.Another reason for the drop in payouts is that more and more organizations are investing in better cyber security measures. This includes things like regular backups, intrusion detection and prevention systems, and employee training on how to identify and avoid phishing scams. As a result, hackers are finding it harder and harder to successfully carry out their attacks, and are therefore less likely to receive a payout.Why This is a Good ThingGovernment organizations such as the FBI do not support paying a ransom in response to a ransomware attack. The drop in payouts is good news for cyber security professionals. With fewer organizations paying ransoms, the incentive for hackers to continue these types of attacks is reduced. Another contributing factor to the drop in payouts is the increased collaboration between the public and private sectors. Law enforcement agencies and cybersecurity companies are working together to track down and disrupt ransomware gangs. This cooperation has led to several high-profile arrests and the disruption of criminal networks, which has had a significant impact on the ransomware landscape. This means that cyber security professionals can focus on more pressing issues, such as protecting critical infrastructure and preventing data breaches.ConclusionOf course, there is still a long way to go before the threat of ransomware is eliminated entirely. However, the drop in payouts is a positive step in the right direction. It shows that victims are becoming more resistant to the demands of hackers, and that the cyber security industry is making progress in protecting organizations and individuals from these types of attacks." }, { "title": "Building Your Own Open-Source SIEM, Part I: AAAAAH!", "url": "/posts/siem-part-I/", "categories": "Guides", "tags": "", "date": "2022-04-18 00:00:00 +0000", "snippet": "IntroThis will be a post series where I discuss the details of an open-source SIEM and how you can deploy it on your own infrastructure. This will heavily focus on Security Onion 2 as it gives us nice out-of-the-box functionality.The aim of this series is not to promote any product(s), but to show you that with a little work and some patience, a lot can be achieved.To SIEM or not to SIEMThe word SIEM has been around for a while, and many companies are still pouring money into paid services so they can have a ‘single pane of glass’ into their infrastructure, however with completely free and open-source tools you can also build your own SIEM. The only catch is that it takes work, but the end result is a highly customizable and highly efficient system that only alerts you when specific conditions set by you are met.Why Security Onion 2Security Onion also has been around a while, although the earlier versions focused more on a singular VM image that’d sniff traffic and replay PCAPs etc. to do basic threat hunting on a local network. The second version focuses on a distributed deployment with multiple nodes that have different functions from each other, which makes it highly scalable and SIEM worthy.Core ComponentsThis section covers some basic component information about Security Onion 2, you can skip this part if you feel like you know enough about how it works.The GridThe Grid is the name Security Onion gives its nodes. It comprises of Forward, Search, Manager, Receiver nodes and they mostly do what their name states. Forward nodes sniff traffic from a SPAN/mirror port on your network using tools like Zeek, Suricata and Stenographer. The traffic is then logged and sent to the Manager node where it’s relayed into Search nodes.Manager node is the head of the whole operation, there is usually a single Manager node in every Grid (though if you’ve managed to configure a multi-manager deployment please let me know lol). This node hosts basic Elasticsearch components like Logstash and …well Elasticsearch. It also queues the incoming logs with its Redis queue and sends them over to Search nodes for ingesting and indexing into Elastic. Receiver node is an alternative Manager node that’s capable of gathering logs. Receiver node was introduced later on to address the scalability issues.SaltStackSaltStack is a very powerful configuration management tool with horrible documentation. I challenge you to find any good documentation on it. It uses YAML syntax to configure its ‘minions’. Salt Master is the Manager node in Security Onion 2 and you can configure other nodes using it. We’ll dive a little deeper into its usage in upcoming posts.ElasticsearchElasticsearch is another open-source project that aims to aggregate, correlate and visualize data in any form. Its main components in an SO Grid are Filebeat, Logstash and Elasticsearch. Filebeat picks up logs on every node and forwards them to (well under normal circumstances) Logstash listeners. Logstash manipulates and filters data then sends it over to Elasticsearch where it can be stored, searched and visualized by Kibana.Other ComponentsThere are other components in Security Onion 2 that comes in handy when doing threat hunting, alert generation etc. Cases works like the JIRA of the platform. Playbook uses sigma rules to generate alerts based on incoming logs. CyberChef allows you to convert data into other kinds of data (think base64’ing or vice-versa), finally FleetDM allows you to query your hosts by deploying Osquery endpoint agents on to them.DeploymentThis part is always fun! But really all you have to do to deploy Security Onion 2 is to follow the documentation. For other unexpected stuff, I tried to cover some of them here.Manager NodeThis node needs to be the first one to be deployed, since all other nodes will connect to it to retrieve their configurations. For best results make sure it has its own IP address and set the hostname to something you like, it’s quite difficult to change it to something else afterwards (might as well re-deploy).Search NodesYou can deploy as many Search nodes as you want, but preferably they should be geographically close to your Manager node if your environment is not on a global scale. We will cover other methods of sending logs into Security Onion 2 by directly hitting Search nodes instead of relaying them through the Manager node, but those methods won’t be covered in this post. Ensure that they have good resources because these are the big boys of your Grid where a lot of processing is done.Search nodes need to be able to communicate with the Manager node directly.Forward NodesForward nodes sniff traffic to generate logs. They can be deployed as both IDS and IPS solutions thanks to Suricata. Running through the installation steps is usually a breeze, unless you want to deploy them in a NAT’d environment. Usually all you have to do is configure a SPAN/mirror port on your most-edge router/switch in the network and plug it into the second network interface you have on the hardware. I’ve tried to sniff traffic before by using a GRE tunnel from another server and royally failed. Let me know if this can be done. Also ensure the NIC that’s sniffing the traffic must be able to handle the traffic passing the switch/router it’s connected to, if you want to avoid packet loss.The NAT Problem and Salt Firewall ConfigurationThe NAT problem I’ve mentioned arises because of SaltStack. When a minion registers itself to its master, all the configuration is supposed to be the same in order for them to successfully communicate. So say you have a forward node with a private IP address of 192.168.23.5 and this gets translated to 80.191.22.5 on the edge of the internal network. After the installation is completed, you have to configure the manager node to allow access to both those IPs in the firewall. Because the Forward node (naturally) thinks its IP is the Private IP it’s assigned, whereas the Manager node only sees the connection coming from the Public IP address. For good measure, ensure the private IP assigned to the Forward node doesn’t change.But wait! Everything in Security Onion is configured via Salt, so you’re not getting away with a simple iptables command. The way the firewall is set up in Security Onion is a little complicated but for good reason. There are hostgroups, portgroups and assigned hostgroups. You don’t need to edit these corresponding files in the Salt configuration, because you can use the provided commandline tools like so-allow. This tool allows certain hostgroups to access certain ports on the node. By default the usage is something like so-allow analyst 192.168.1.1 which allows the mentioned private IP access to analyst ports. What are analyst ports? Well they’re defined here in the Salt configuration. For more advanced firewall configuration, you can use so-firewall. Back to our example, you need to include the Forward node’s IP addresses in minion and sensor portgroups.You can use the following commands to achieve this:so-firewall includehost minion &amp;lt;IP&amp;gt;so-firewall includehost sensor &amp;lt;IP&amp;gt;so-firewall applyEnsure that you add both IPs with the first two commands to both groups so they can communicate. I wanted to cover this section, because this was a common problem amongst the users.After DeploymentThe initial deployment is a process that you’ll get used to after a while, but make sure to document every issue you have faced and solved for your own good. Please help the community by sharing them as well.Assuming you have a working Grid now, get a feel of the UI and read more about the documentation. It is an ever-evolving project that deserves the attention in my opinion. Feel free to check out some of the guides I’ve shared with the community here.In the upcoming posts I’ll get into the nitty gritty of managing an open-source SIEM, this will include connecting an external Logstash instance to the Search nodes for scalability (you can read it now here), configuring SSL certificate verification between the external Logstash and the Search nodes, writing new Ingest Pipelines and Grokking. Hopefully by the end of the series, you’ll be able to ingest any kind of data to your open-source SIEM by using the ELK pipeline, generate alerts from them and send them to other sources like Slack. Let me know about your opinions and suggestions. Thanks for reading!" }, { "title": "Implementing File Integrity Monitoring with Osquery", "url": "/posts/fim-osquery/", "categories": "Guides", "tags": "", "date": "2022-02-21 00:00:00 +0000", "snippet": "In this post I’d like to talk a bit about file integrity monitoring and how you can implement it using Osquery. Let’s jump in.Requirements: Osquery installation Basic understanding of the Linux filesystemIntegrityOne of the main legs of the CIA triad is integrity. Maintaining the integrity of system files is important because these files decide the outcome of the binaries that we execute. Alongside these files, it’s also necessary to monitor the binaries on the system for changes. Even though the built-in binaries might get updated/modified over time, it is necessary to monitor the changes to determine the deviations from “normal”, which may be an indicator of a compromised system.Installing OsqueryIn order to follow along this guide, you need to install Osquery on your favorite distribution. The default method of installation will provide two binaries on your system osqueryi and osqueryd. As you might infer from the names, osqueryi provides an interactive interface to run queries while osqueryd is the daemon for the software. As of this writing, Osquery is a completely free and open-source software.If the installation is done correctly, you should be able to run osqueryi from any directory since by default it’s added to the PATH. Run osqueryi to start the interactive Osquery shell and then you can use .help to better understand what’s available.FleetDMFleetDM is another free and open-source project, though some pricing exists for extra features. This software aims to connect all your Osquery daemons to a centralized server, where you can run, schedule, and create packs with queries. This provides both flexibility and scalability of your Osquery deployment. It is not necessary to install this to follow along the guide, but it’s a rather useful software if you’re planning to deploy Osquery on your production environment.TablesOsquery provides hundreds of tables that you can query to gather information about your system. The language used to query these tables is SQLite. There are two main types of tables in Osquery. Evented tables and …well, tables. Regular tables hold information about the system that can be queried any time, while evented tables will help you generate logs based on certain events. We won’t delve into too much detail about the configuration steps, but it would be useful to check out the documentations in case you get stuck.Evented TablesAlthough evented tables may sound more enticing, they’re more performance hungry and may impact your server’s core functionality if configured incorrectly. One great example that can help us with file integrity monitoring is the file_events table. This table (when enabled) will track the changes on the filesystem and keep this information in the virtual database so that they can be queried to gather precise information about the changes.Though I must admit, saying “Yeah, just use this table!” would be lazy. But this is the table that you want to query when looking for filesystem changes and to see what exactly changed within the file. You can specify which directories and sub-directories you want to monitor and it will check only for those files/directories.Implementing FIM Without an Evented TableOsquery also provides us with other tables that contain the information we need and these are less resource hungry when queried, since they only check the system when the query runs. You can follow the query profiling documentation to test your query’s performance impact on any given system.Now onto to the real deal. One of the regular tables that come bundled with Osquery is the file table. This is a table that allows you to see quite a bit of information about a file, given that it’s path or directory is specified. For understanding what we’re doing next, I have to talk about “inodes”.inodesInode stands for “index node” and inodes in the Linux filesystem hold information about every file such as where on the disk the file is, attributes of the file, metadata, and the information that every digital forensic analyst loves to see - the macb information. Every file on the system has a corresponding inode that represents the file. macb is not an official name, but it’s one of the attributes of every file.m = Last Modifieda = Last Accessedc = Last Changedb = BirthYou can stat a file in Linux to see this information about a file. Like in the following example:root@localhost:~# stat test.conf File: test.conf Size: 283 Blocks: 8 IO Block: 4096 regular fileDevice: 800h/2048d Inode: 9738 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2022-02-21 20:16:28.572835183 +0000Modify: 2022-02-21 20:16:20.908891089 +0000Change: 2022-02-21 20:16:20.908891089 +0000 Birth: -As you can see, the Birth date might not be registered for every instance. mtime and the ctime might be a little confusing, but mtime represents the last time the file’s contents were modified, while the ctime will show you the last time the file’s property changed. ctime will change every time the mtime changes, but it will also change when the file’s permissions, location or name changes.File Table and Files To Look ForOsquery’s file table includes the macb information about a file. Using these columns, we can detect when a file is modified. This table can also look for the attributes of the directories directly, which can help you understand if the contents of a directory has changed as well.This is the different approach we’re going to take in implementing our file integrity monitoring. Key things about the whole ordeal: When a file inside a directory is modified or when a new file is created within a directory, the mtime of the directory also changes When a file is modified it’s mtime changes duhUsing these 2 key factors we can implement two differentially scheduled queries to achieve our goal.Monitoring FilesSELECT path, mode, mtime FROM file WHERE path IN (&#39;/etc/passwd&#39;, &#39;/etc/gpasswd&#39;, &#39;/etc/group&#39;, &#39;/etc/shadow&#39;, &#39;/etc/gshadow&#39;, &#39;/etc/sudoers&#39;);You can monitor the above-mentioned files for detecting changes in them, since they’re the files that are less frequently modified and they hold sensitive information about the system.There are more files in the /etc directory like initialization scripts that we can monitor, but I didn’t add those for the sake of simplicity. You can add more files you want to monitor between the parentheses to include them.Monitoring DirectoriesAlthough file_events may provide more precise information about the changes made to the directory contents, it’s still useful to monitor them with the file table since these directories are only modified when updates take place or new files are created.SELECT path, mode, mtime FROM file WHERE path IN (&#39;/usr/sbin&#39;, &#39;/usr/bin&#39;, &#39;/bin&#39;, &#39;/sbin&#39;, &#39;/boot&#39;);If you’ve noticed, we’re still using the path column of the file table to specify the location we want to monitor, this is because looking at the directory’s path itself can help you monitor the mtime of the directory itself. Any change in this mtime value indicates a change in either directory itself or the contents of the directory.That’s all! Feel free to message me on LinkedIn if you have any questions or issues you’d like me to fix. Cheers!" }, { "title": "Linux Memory Forensics", "url": "/posts/linux-memory-forensics/", "categories": "Forensics", "tags": "", "date": "2022-01-28 00:00:00 +0000", "snippet": "We can sum up forensic analysis as the different methods used in evidence acquisition, analysis of evidence, and documentation of the consequences of a security incident. After a confirmed security breach, a forensic analysis usually takes place to understand better what went on in a compromised system. There are numerous sources of evidence that you can analyze to make defensible claims about the source of an incident; however, I’ll only do a hands-on memory analysis of a compromised Linux system to demonstrate some of the methodologies and tools you can use.MemoryRAM, by nature, is volatile. It requires constant power to go through it to function, and it gets reset every time a system reboots. Linux keeps the data stored in memory under the /dev/mem directory; however, it’s impossible to extract artifacts from memory using this partition directly in more recent distributions. This is because starting in Linux kernel 4.16, an option (CONFIG\\_STRICT\\_DEVMEM) gets enabled by default to disallow access to this sensitive partition.Although this makes it harder to acquire the memory image, it also makes it more difficult for adversaries (and inexperienced users) to cause devastating damage to the system. An attacker with root access to the system may use the mem device to inject code directly into the kernel if this option is disabled.I’ve spun up a Debian 9 server with the hostname forensics in one of our data centers for this demonstration. I configured the forensics box to be an example of a building and analysis environment. Although it’s not necessary to do these on an external machine, tampering with a computer that holds evidence is inadvisable. Here are the steps to our analysis: Create a Volatility profile for a compromised system using a machine with the same OS and kernel build/version. Dump the memory with your tool of choice (AVML in this demo). Inspect the dumped memory using the profile you’ve created for Volatility with the help of plugins.WarningI will use the Python 2 repository of Volatility for demonstration purposes because of the compatibility issues currently in progress with Volatility 3. If you’d like to follow along with the guide, please do so at your own risk.RequirementsBy default, Debian 9 will lack some of the tools we’re going to use in this demo. It’s recommended to install all of them with the following command before proceeding with other instructions:sudo apt install make git zip dwarfdump linux-headers-$(uname -r) python-pip python-distorm3 python-cryptoVolatilityThe Volatility Framework is a completely open collection of tools implemented in Python under the GNU General Public License to extract digital artifacts from volatile memory (RAM) samples.It’s important to ensure that the correct Volatility profile gets used when analyzing a memory dump. A profile is a file containing information about a kernel’s data structure and debug symbols that can be used to parse a memory image properly. Luckily creating a profile with Volatility is quite simple. You can also check out the repository of Volatility profiles for some pre-built profiles.Building A ProfileAfter installing the necessary tools, we can begin building our Volatility profile for the machine it’s running on.git clone https://github.com/volatilityfoundation/volatility ~/volatilitycd ~/volatility/tools/linux/makezip ~/$(lsb_release -i -s)_$(uname -r).zip ./module.dwarf /boot/System.map-$(uname -r)cp ~/$(lsb_release -i -s)_$(uname -r).zip ~/volatility/volatility/plugins/overlays/linux/python ~/volatility/vol.py --infoThe initial line (1) will clone the Volatility repository into the user’s home directory. By going into the (2) ~/volatility/tools/linux directory, we can use make (3) to recompile the modules of the kernel. It’s important to have the kernel headers downloaded beforehand, otherwise this process might fail.This results in a module.dwarf. Then the next command (4) uses this module to read the system map from /boot to generate the profile we need to use in Volatility. We can then copy this profile (5) over to the right directory, so that Volatility can use it. Finally, to verify our profile is properly loaded into Volatility we can run Volatility once with the info flag (6). If all the steps are successful, we should see our custom profile in the Profiles section of the output.Installing a Hidden Kernel ModuleFor this example I’ve used HiddenWall to generate a hidden Linux Kernel Module (LKM), named it ‘cantfindme’, and loaded it onto another Debian 9 Linode with the same kernel build/version as the ‘forensics’ machine. Although the module is loaded, it can’t be seen when lsmod or modprobe is executed on the system:Memory AcquisitionThere are great tools that you can use to dump the memory in Linux; however, in this guide, I’ll go with AVML (Acquire Volatile Memory for Linux) since LiME is covered frequently on the web. AVML is an open-source memory acquisition tool for Linux made by Microsoft. You can find the latest release here and download the binary to the machine from which you want to dump the memory. Remember that the computer we’re dumping the memory from must have the same kernel/OS build and version as the Volatility profile we have generated previously.In a real-life scenario, it’s important not to tamper with a compromised system to ensure the evidence we collect may be admissible in a court of law. It’s also important not to compress any images whenever possible because bit-by-bit acquisition may provide data that a compressed image may not.After downloading the AVML binary onto the home directory, you can use the following command to dump a system’s memory to the home directory.sudo ~/avml ~/output.limeAVML will dump the memory in LiME format, so that we can begin our analysis with the Volatility profile we’ve created. You can also check out the size of the dump to ensure it matches the total RAM on the device. Volatility shouldn’t tamper with the memory dump, but it’s better to make a copy of the file and to analyze the copied data instead of the original after ensuring that their hashes match.After dumping the memory of the ‘pwnd’ box, I’ve transferred it to the forensics box for analysis.Volatility PluginsVolatility offers numerous plugins to aid the forensic analyst. You can find a list of these plugins in their Github page. By using Volatility plugins we can get a quick overview of the memory image. The command format for analyzing a memory image can be found below:python ~/volatility/vol.py -f &amp;lt;path_to_memory_dump&amp;gt; --profile=&amp;lt;profile&amp;gt; &amp;lt;plugin_name&amp;gt; &amp;lt;plugin_options&amp;gt;Here’s the output from the plugin linux_hidden_modules that lists the hidden loaded kernel modules from the memory image:This plugin can help you find hidden Linux Kernel Modules that may be malicious. Even when these modules can’t be seen when you run lsmod on the system, they can both be detected and extracted from a memory dump. You can use the linux_moddump plugin to dump the kernel modules either by specifying their name in a regex pattern or by specifying the base address of the module in the memory image:Taken from the Linode blog post I’ve authored." }, { "title": "Import hashing (aka imphashes)", "url": "/posts/imphashing/", "categories": "General", "tags": "", "date": "2021-10-24 00:00:00 +0000", "snippet": "In our fuzzy hashes post, we learned about fuzzy hashing and how it’s a different approach to malware classification. In this post we’ll explain what an import hash is and how we can utilize it in our blue teaming efforts. But first we need a quick introduction to DLLs.DLLs (Dynamic-Link Libraries) are libraries specific to Windows systems. These libraries are imported whenever an executable needs basic functions like creating a file, deleting a file or simply making a network connection. A library is a file with pre-written code that can have all kinds of functionality. So instead of including the whole functionality, most software will import these libraries to use them when needed. Making it available for malware to do the same.For this tutorial we’re going to need a couple of things: Either PeStudio or Pefile module for Python (You can get it via pip!) If you’re using Pefile module, you will need Python3 on your system Two portable executables for analysis (exe files) NOTE: Downloading a ransomware in exe format on your Windows system is highly inadvisable. Please use a Linux VM for your disk’s well-being.For my example I grabbed the CryptoLocker ransomware from theZoo GitHub. PeStudio and pefile are great tools for analyzing portable executables, but what is import hash really?Import hashes are values, calculated based on which libraries are imported when a software is loaded onto memory. It takes the order of the loaded libraries into account and provides us a value that we can use to compare files. Typically, if a malware is compiled from the same source and has the same address table, their resulting imphashes will be the same. This allows us to determine if a sample we already have is related to the ones that we collect. Getting the imphash value for a file is really simple.For PeStudio, if you drag and drop the file, it will calculate the imphash for you. For those of us who don’t like the easy way, let’s create a python script that we will call get\\_imphash.py. All you need is a few lines of code using the pefile module.import pefileimport syspe = pefile.PE(system.argv[1])print (pe.get_imphash())Let me explain what the code does:1 – We import the pefile module itself and the sys module so we can specify a file path to the script.2 – We create a pefile object named pe and we specify it to be the system argument we’re going to provide in the terminal.3 – We print the imphash of the specified file, with the help of pefile module.When you open up a terminal, you can run the script with Python3 like so:python3 get_imphash.py /file_path.exeI’ve mentioned I’ve grabbed the CryptoLocker from theZoo for this post. The reason being that CryptoLocker was a ransomware/trojan and we have two different samples with same functionality. When you unzip the package you will get two executables. I suggest using a Linux VM for this, since accidentally running the exe might ruin your day. Now let’s compare the two files.Comparing the two files with their sha1 hashes, we can see that they’re different files:Comparing the fuzzy hashes of the files, we can see that they’re completely different:But when we use import hashes, they look identical:This is where import hashes come in handy. If you need to classify a suspicious file and the malware family it belongs to, you can import imphashes into your daily analysis routine. Stay tuned for more and leave any questions below as a comment. Thanks for reading! BONUS: Here’s a really cool video by Eric Conrad about this and more!Taken from our old blog over at hackerspot.net, written by me." }, { "title": "Building Your Own Dynamic Malware Analysis Lab", "url": "/posts/malware-lab/", "categories": "Guides", "tags": "", "date": "2021-06-21 00:00:00 +0000", "snippet": "Welcome back to my personal blog!In this blog post, I will introduce a couple of tools that you can use to analyze malware behavior at home. You will require a computer that can handle 2 virtual machines at the same time, so that we can create an infected machine and another machine which will act as the gateway for the infected machine. This second virtual machine will let us capture and analyze network packets sent by the infected machine. This guide assumes you’ve done the static analysis on the file and you’re trying to figure out what the malware exactly does, before trying to reverse the binary. Note : You can use theZoo to find malware samples, in this post we will analyze the WannaCry ransomware. Please do not run/download any malware directly on your host OS, this may result in data loss and acute nervous breakdowns. I’m not responsible for nuclear wars and your computer becoming firewood for winter.Requirements: A computer that can handle 2 Virtual Machines at the same time A malware specimen (check out theZoo!) An older Windows image for your preferred virtualization software Your preferred Linux distribution’s virtual image (debian based would be better) On Windows machine: Python, Noriben, ProcMon On Linux machine: inetsim, WiresharkBefore we set this all up, let me demonstrate what we’ll do with a badly drawn picture:Now this might look a little disencouraging if you’re a beginner and just want to have fun. But I will try to walk you through all of these in a simple manner.To install the requirements, we need to download them onto the Linux machine and then transfer them to the Windows machine. This is because older versions of Internet Explorer is blocked by many websites, since it is commonly used to exploit vulnerabilites.Let’s grab the python (Python3) package for Windows from its official webpage. Then we’ll need to clone the Noriben and Yara-Rules repositories from GitHub, on our Linux machine.// These lines will install git if you don&#39;t already have itsudo apt updatesudo apt install git// You should install python on the Linux machine as well if you don&#39;t have itsudo apt install python// These lines will clone the Noriben &amp;amp; Yara-rules repo which is optionalgit clone https://github.com/Rurik/Noribengit clone https://github.com/Yara-Rules/rulesI’ve created a folder unironically named “WinMachine” on my Linux desktop and I will store the files needed there for this guide. Now, Noriben needs ProcMon to function, which stands for Process Monitor and does exactly what the name states. This is a tool that was first published by Sysinternals and is now used by Microsoft as well. Let’s grab the file from Microsoft’s official website. Then we need to copy the contents into the Noriben folder, in order to make Noriben perform properly. I’ve also compressed the whole folder after this, for easy access from the Windows machine.We’ve talked about Yara in a previous post. Yara will let us narrow down our search in this example by matching strings from created files in the system.Let’s get our malware sample from theZoo on the Linux machine. You can grab any sample you want that targets Windows systems, but for this guide I’m using the famous WannaCry. Additionally you can do a checksum for the file you’ve downloaded to make sure it’s not tampered with.Now we need to install Wireshark and inetsim on our Linux machine. You can install Wireshark using apt, the built-in package manager in debian based distributions.sudo apt install wiresharkFor inetsim, simply go to this link and download the latest version. You will get a tarball (.tar.gz format). Extract it using the following command in the same directory.tar -xzvf inetsim-1.3.2.tar.gzThis command will extract the contents of the file, so that we can run inetsim to simulate basic network features on the Linux machine. Then let’s take our virtual machines off the network by going into the network settings of your VM software. You need to perform this change on both of the machines. Simply change the network interface to “Host-only Adapter”.Then we need to put the two machines into the same network by changing their IP addresses. In the Linux machine, you can use ‘ifconfig’ or ‘ip addr’ to make these changes, I will only demonstrate the ifconfig here.When you run the ifconfig command, it gives you the network interfaces that are attached to your computer, in this case the virtual machine. Since “lo” is the loopback address, we will need to configure eth0’s IP address as ‘192.168.1.10’.After bringing the interface down, changing the IP and bringing it back up, you should see that the IP address of the interface has changed. Now let’s configure the Windows machine. By now it should be on Host-Only Adapter mode. You can configure the Windows machine’s IP as 192.168.1.20 and the default gateway as shown below.You should be able to ping the Linux machine from the Windows machine now. Open up a commandline on the Windows machine and try the following.If for some reason the ping doesn’t work, this means there is no connectivity between the machines and you would need to troubleshoot the problem.Now let’s serve our file directory on the Linux machine. You need to open a shell in the directory you’ve stored the Windows files and do the following.Now, since we’ve setup the Linux server’s IP as 192.168.1.10, this python command will run a basic http server on that IP. You need to open a browser on the Windows machine and go to 192.168.1.10 as shown below.If you see the directory listing, this means you’ve configured everything correctly so far. Time for a KitKat!There are a couple of things left to do on the Windows machine. Download the files from the Linux machine’s server Disable Windows Defender Install Python (Add to PATH as well) Extract Noriben and Yara Rules if you’ve archived them like me Take a snapshot of the Windows VM if you want to use it again in the futureBefore running any malware, let’s configure inetsim and Wireshark on the Linux machine.To run inetsim, go to the directory you’ve extracted it into, then open up a shell and type:sudo inetsimYep, it’s that simple. You should see a lot of output from inetsim saying it’s starting all the services for you.Next, let’s open up Wireshark with the shell to run it as root.sudo wiresharkWhen you open up Wireshark, you should be met with the capture interface. Select the interface you need to capture the network flow in (eth0 in this case). It will start capturing packets for you.We will need to start Noriben as well, before running any malware on our poor Windows machine. You need to start a commandline with admin privileges, change the directory to where Noriben resides and then run Noriben with the optional yara flag. After the yara flag, you need to specify where you’ve put the yara rules in. In my case it’s in a folder named ‘malware’.If we’ve configured everything correctly, we should be ready for the fun part. Execute the malware with admin privilieges and watch the world burn, without actually burning it!In depth analysis of all the files you get in the end of this, is actually where the real work begins. However it will not be covered under this post, because this post has been long enough. Using this setup, you should be able to capture network packets and processes created by a malware, further helping you understand the goal of an attacker. Stay tuned for more and please get vaccinated before you get infected! (Jokes aside, update your systems)Taken from our old blog over at hackerspot.net, written by me." }, { "title": "Android Security Issues, Brought to You by OEMs", "url": "/posts/android-security-issues/", "categories": "Thoughts", "tags": "", "date": "2020-10-27 00:00:00 +0000", "snippet": "In this post I’d like to dive into the Android devices I’ve used in the past and how they all had inherent security issues caused by OEMs making a ton of customizations, adding their bloatware and more.As an Android enthusiast, I got into rooting/flashing with my first smartphone, a Sony Xperia Z3 Compact After bricking it the first time I’ve tried, I knew I was doing something wrong but I kept learning because back then rooting your phone meant more control and cool features that had swag. Here’s a small list of Android phones I’ve used in the past: Sony Xperia Z3 Compact Huawei P8 Lite (2017) Xiaomi Mi A2 Lite Xiaomi Mi A3 Google Pixel 3a Motorola Moto X4 LG G7 ThinQ#1 – Bad Update CyclesSony made a concept firmware for my beloved Z3 Compact, showcasing Android 6.0 (Marshmallow), but then decided not to update the phone to a stable version.Android phones are infamous about their painfully slow updates and this is a big security issue, since most phones go outdated with no way to update them. Having up-to-date security patches is crucial in our modern world.#2 – Bloatware and Unremovable System AppsAndroid phones that have a custom skin also come with the OEM’s pre-installed bloatware. Stock Android or the open-source version of it doesn’t have any of this. OEMs try really hard to obtain every bit of data they can collect about you, so that they can sell this data. They install their own versions of the stock apps alongside the stock ones and expect you to use theirs, or at least give the same permissions to them. By doing this and agreeing to countless Terms of Services, you give permission to the phone’s manufacturer to take a peek at your life, just like Google does. I don’t think a weather app would need microphone permissions.#3 - Custom Bootloaders Like KnoxYou might be thinking, Knox? A security issue? Not by itself. But making modifications to the open-source and the community supported kernel and bootloaders, then making it a closed-sourced project (just like iOS) comes with its problems. Here’s a snip from BlackHat 2020 that I’ve attended in August, explaining how to exploit the Secure boot system in Samsung devices, all while the bootloader is still locked and Knox is untripped.This doesn’t end there. I’ve used a Xiaomi Mi A2 Lite before, which is an Android One device. Android One promises a secure and up-to-date platform for you to use. It promises two years of guaranteed firmware updates and three years of security updates. Not only Xiaomi could not deliver these promises, but also they left users with a lot of bugs and even bootloops with the Android 10 update. After waiting for months from the initial release date, the Android 10 update arrived and it literally bricked half the devices that had been updated via OTA. But wait, that’s not all…Because Xiaomi changed the kernel and the bootloader of their Android One device, you could literally bypass the factory reset when you unlocked the bootloader. Simply by rebooting the phone back into fastboot mode, right after issuing the bootloader unlock command, the phone would boot into the fastboot mode and bypass the bootloader unlock security mechanism entirely. This meant the phone that was supposed to be secure and up-to-date, was neither secure nor up-to-date.#4 – OEM backdoorsHaving used an LG G7 ThinQ (US – unlocked version is still on Android 9 as I write this), I knew I had to unlock the bootloader and root it or flash a custom firmware. Which I did, but there was only one way of properly unlocking the bootloader.See, most OEMs don’t want you to unlock the bootloader of your device and/or flash another firmware. This means that they’re losing money, on a device that they’re selling you. Hence, most companies will prevent you from unlocking the bootloader on the device that you own entirely. Do you know how they fix a software problem when you send it to warranty? Since we can’t unlock the bootloaders, they shouldn’t be able to as well, right? Wrong.An “engineering” file that was leaked from LG, can be temporarily flashed to many other LG phones’ abl partition using EDL (Emergency Download Mode). This image allows you to issue the bootloader unlock command and then flash whatever image you like to the other partitions. This also allows the phone to be rooted and forensically acquired.Personally, I really like the way Android works and its customizability. But it is nearly impossible to say that a phone is really secure because of the issues I’ve mentioned and more. I believe OEMs should let users decide what to do with their own devices and allow them to officially unlock the bootloader, especially if they’re lazy enough to not update them. If you want to read more about security and computer forensics, stay tuned! Leave a comment to share your thoughts as well, happy holidays!Taken from our old blog over at hackerspot.net, written by me." }, { "title": "Fuzzy Hashing vs Regular Hashing", "url": "/posts/fuzzy-vs-regular-hashes/", "categories": "General", "tags": "", "date": "2020-10-20 00:00:00 +0000", "snippet": "In this post we will compare fuzzy hashing to regular hashing. Now let’s begin with digestion which is what people usually refer to when they say hashing.Hashing is a mathematical one-way function applied to a binary/data to come up with a unique string that identifies the file at hand. Any changes to the file (even just a ‘bit’) change the resulting hash drastically, and hence this procedure is used to identify or verify the integrity of files. In PowerShell, you can use the Get-FileHash command with the -Algorithm flag to specify a hashing algorithm and hash a file. In Linux, it’s as simple as specifying the algorithm and appending the sum at the end, and specifying the directory. Hashing lets us know if a file has been tampered with or in malware analysis, lets us know if the file we have is the same as another.//PowerShell command:Get-FileHash -Algorithm sha1 &quot;C:\\Users\\user\\Desktop\\file.exe&quot;//Linux command:sha1sum ~/Desktop/file.shYou can use the hash of a file to compare it with other hashes already uploaded in VirusTotal to see if you have a match. This would mean the same hash has been uploaded before and if there are matches by antivirus scans, it’s likely what you have is a common or known malware.Since hashing results change a lot when a file is tampered with, this makes it easier for bad actors/actresses to avoid getting caught. Simply by changing arbitrary data in a malware, the corresponding hash can be altered and therefore it can go unnoticed by antivirus scans. This is where other types of hashing comes in handy.Fuzzy hashing is a different approach to hashing. It hashes a file in blocks and then appends them to each other. This way even if an arbitrary section of a file is tampered with, the resulting hashes will be similar if not the same. Let’s demonstrate how this works to understand it better. For this demonstration we will use ssdeep on a Linux terminal.&amp;lt;/figure&amp;gt;Now let me explain what we’ve done here, command by command:1 – We created a file named file.txt.2 – We echo’ed a sentence into the file so it is not empty.3 – We took the hash of the file with md5 algorithm.4 – We took the fuzzy hash of the file with ssdeep, but ssdeep complained that this is a really small file.5 – We appended an exclamation mark to the end of the sentence, just to tamper with the file.6 – We took the md5 hash of the file again after tampering.7 – We took the fuzzy hash of the file again after tampering.What we really care about here is how fuzzy hashing produces different results than regular hashing. As we can see here the regular hash changes by a lot, even though we’ve added only one character. This is called diffusion. But with fuzzy hashing we can deduce that the results aren’t that different. Let’s take a closer look: 840b362490d9e5cde50498cac3b72c62 : Original MD5 ac36253fbbc5997a33c6f82ef9041b0e : Tampered MD5 aQEXRIn1LmxTXsPlhvn : Original Fuzzy Hash aQEXRIn1LmxTXsPlhvG : Tampered Fuzzy Hash This is where fuzzy hashing comes in handy. While the regular hash of the file comes out substantially different than the original one, fuzzy hash of the file proves that there are a lot of identical sequences of bytes in both files.Most malware authors try to obfuscate and change their code, so that their code goes undetected by antivirus scans and regular defense mechanisms. Regular hashing wouldn’t let us determine if we have a similar malware at hand, it only works if we have the same exact file. But by using fuzzy hashes, we can determine if a suspicious file we have is related to previous samples we’ve collected. For more information on ssdeep, you can visit the documentation page. Thanks for reading!Taken from our old blog over at hackerspot.net, written by me." }, { "title": "Using YARA", "url": "/posts/using-yara/", "categories": "Guides", "tags": "", "date": "2020-10-15 00:00:00 +0000", "snippet": "YARA is a multi-platform tool that lets you identify patterns in files. By identifying particular strings and signatures in a binary, you can determine the type of the file and gather a lot of information about it. It’s easy to use and customize for your own purposes. It’s mostly used in malware analysis.Prerequisites: YARA from the linked GitHub page or apt-get A portable executable to examine. Check out theZoo for malware samples. Text editor of your choice You can find a lot of cool pre-written rules in YaraRules Project’s Git.After installing YARA on your computer/VM, you can simply create a file to write rules that dictate YARA what to look for in a binary. A YARA rule consists of 3 parts: meta strings conditionNow let’s write a simple YARA rule that checks if the file is written for Windows systems. Windows executables contain the letters MZ at the first two bytes (or 4D 5A in hex). These letters refer to Mark Zbikowski, who was a leading developer in MS-DOS. The first thing we need to do is to declare the rule with the rule keyword. Simply type it into the file.rule is_win_executable {}We’re going to insert the meta, strings and the condition into the curly brackets. Meta is, as the name suggests, information about the rule and what it does. Adding meta is not necessary. Now let’s add meta to give information about the rule.rule is_win_executable { meta : author = &quot;dummysec&quot; description = &quot;Checks if the file is a Windows executable.&quot; version = &quot;0.1&quot;}Now let’s add the strings we want YARA to look for in the files. The string we’re looking for is MZ.rule is_win_executable { meta : author = &quot;dummysec&quot; description = &quot;Checks if the file is a Windows executable.&quot; version = &quot;0.1&quot; strings : $a = &quot;MZ&quot;}Lastly we need the condition to be set. We want YARA to look for the string “MZ” in the first two bytes.rule is_win_executable { meta : author = &quot;dummysec&quot; description = &quot;Checks if the file is a Windows executable.&quot; version = &quot;0.1&quot; strings : $a= &quot;MZ&quot; condition : $a at 0}Our rule is ready to use! Make sure to save the file and we’ll open up a terminal to start looking for MZ in the first two bytes. You can use the following command to utilize the custom rule you’ve written:yara -r custom_rule.yar ./file_dir-r flag specifies the rule and the last part specifies the location of the file on the disk. You can add multiple rules in a single rules file and YARA will look for all of them in a binary. You can add multiple strings and conditions with Boolean values to customize and fine tune your queries. By appending keywords like nocase to the strings, you can broaden your results. Finally, you can use question marks as wildcard characters.You may be asking yourself, why not use xxd to read the file and then pipe the results to grep? Grepping the xxd reading of a file is basically what YARA does. But with the custom rulesets and conditions set by the researcher, YARA proves useful by automating most of the stuff and saving time. Looking for known file signatures and functions can help you determine what the file is written for.In the upcoming posts, we’ll take a look at fuzzy hashing and import hashing. Stay tuned!Taken from our old blog over at hackerspot.net, written by me." }, { "title": "Python Script to Send a File Hash to VirusTotal", "url": "/posts/python-hash-vt/", "categories": "Guides", "tags": "", "date": "2020-10-08 00:00:00 +0000", "snippet": "Welcome to hacker0ni.com! In this post, I will demonstrate how to write a simple Python script that will hash a file on your Windows system and check if it’s malicious by using VirusTotal’s API. Let’s get started!Requirements: Python 3+ installed on your system A free VirusTotal account Mad coding skillz or the ability to read this postTo create a python file, you can open up IDLE (code editor that comes with Python) and go to “File &amp;gt; Save As…” and name your script as you like.You’re gonna need an account on VirusTotal to use their API. By signing up, you will be provided with an API key that you need to take note of. We will be hardcoding your API key into the script. Do not share this API key with someone else.Fire up IDLE or your choice of text editor and open up the .py file you’ve created. We’re gonna need to import 3 libraries to make this script work. so let’s import them first.import sysimport requestsimport hashlib We need the sys library so we can read files from the system. We need the requests library so we can make an HTTP request to VirusTotal’s servers. We need the hashlib library so we can hash the files we read from the system. Note: If you’re having issues with the libraries mentioned, you might need to install them first using pip (pip installs packages). If you’ve added Python to PATH while installing it, you can open up a PowerShell terminal and install pip with python -m pip install -U pip command, then using the pip install &amp;lt;package_name&amp;gt; command in the terminal, you can install the packages/libraries you’re missing.After importing the necessary libraries, we need to specify the variables we will need.file = input(&quot;Please enter file directory: &quot;)file = file.strip(&#39;&quot;&#39;)url = &quot;https://www.virustotal.com/vtapi/v2/file/report&quot;BLOCKSIZE = 65536The first line takes our file’s directory as input when we run the code. The second line removes the quotation marks that come with the directory. The third line is the url we need, to use the VirusTotal API v2. The fourth line creates a variable that we will use during the hashing process. Now we’re going to need to create an object that hashes the file we’ve specified.hasher = hashlib.sha1() with open(file, &#39;rb&#39;) as afile: buf = afile.read(BLOCKSIZE) while len(buf) &amp;gt; 0: hasher.update(buf) buf = afile.read(BLOCKSIZE) fileHash = str(hasher.hexdigest())We’re using the SHA1 algorithm, but you can use MD5 or SHA256 based on your preference, simply replace “sha1” with the algorithm of your choice in the first line. The rest of the code is a python specific way of reading a file from a directory on the system, the BLOCKSIZE is the amount we’ve specified before. It basically opens the file, reads it in binary format of 65536 bit blocks and writes it to the variable buf. As long as the buf variable is bigger than zero, it updates the hasher with data it read from the file, aka the variable “buf”. Then at the last line it digests (hashes) this data to come up with the hex value of the hash, then converts it to a string we can use.Next, we’re gonna need to create parameters that will supply our API key and the hash to the VirusTotal server.parameters = {&#39;apikey&#39;: &amp;lt;YOUR_API_KEY_HERE&amp;gt;, &#39;resource&#39;: fileHash}Don’t forget to replace the &amp;lt;YOUR_API_KEY_HERE&amp;gt; with your own API key as a string like so: ‘3DA541559918A808C2402BBA5012F6C60B27661C’. Add the following lines of code to make the HTTP request.response = requests.get(url, params=parameters) response = response.json()The first line will use the imported requests library to make an HTTP GET request to the API, with the url and parameters we’ve provided. The second line will convert this response into JSON, so we can manipulate it. Now all we need to do is to print the parts of the JSONized response we’ve received from the server. You can check the example response to find what you need from the response. Here, we’re going to check the response code and print a message or the response itself accordingly.if response[&#39;response_code&#39;] == 0 : print(response[&#39;verbose_msg&#39;]) elif response[&#39;response_code&#39;] == 1 : print(response[&#39;scans&#39;]) print(&quot;Detected: &quot; + str(response[&#39;positives&#39;]) + &quot;/&quot; + str(response[&#39;total&#39;])) else : print(&quot;Alien behind you!&quot;) exitmsg = input(&quot;Press any key to exit!&quot;)The if statements check the response code from the JSONized response, if it’s ‘0’, it prints the verbose_msg found in the response. This means the hash was not found in the database. If the code is ‘1’, it means the hash was found in the database, so the script prints all the data it got back and how many positives it got out of total scans. If the response code is something else, then it complains that aliens have invaded the earth. Then it prints an exit message, so that you can read the results without the script terminating right away. You can find the full script on my github. NOTE : If a hash comes clean from VirusTotal, it doesn’t necessarily mean the file is safe to use. By changing arbitrary data in a file, the corresponding hash can be changed drastically. For better results, you should upload the file itself so that it can be scanned fully. Even then the results might be misleading.Thank you for reading. Please share your opinions about the post. Cheers!Taken from our old blog over at hackerspot.net, written by me." } ]
